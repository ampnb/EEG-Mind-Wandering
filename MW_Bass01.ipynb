{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNG1BtCoBVP8jg0Gx9uhZkW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ampnb/Mind/blob/main/MW_Bass01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mne"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKqM10Gp9sgG",
        "outputId": "4253ef5a-e086-455c-c198-5fe8e97e9d90"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mne\n",
            "  Downloading mne-1.4.2-py3-none-any.whl (7.7 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/7.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m5.5/7.7 MB\u001b[0m \u001b[31m166.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m167.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m105.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.10/dist-packages (from mne) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from mne) (1.10.1)\n",
            "Requirement already satisfied: matplotlib>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from mne) (3.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne) (4.65.0)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne) (1.6.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne) (23.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne) (3.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (2.8.2)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (2.27.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne) (2.1.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.4.0->mne) (1.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4)\n",
            "Installing collected packages: mne\n",
            "Successfully installed mne-1.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyeeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twlsTGBDcPJC",
        "outputId": "c3cd9bd8-bdc7-4857-e8d2-cedf3d534d06"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyeeg in /usr/local/lib/python3.10/dist-packages (0.0.2)\n",
            "Requirement already satisfied: websocket in /usr/local/lib/python3.10/dist-packages (from pyeeg) (0.2.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from pyeeg) (1.6.0)\n",
            "Requirement already satisfied: gevent in /usr/local/lib/python3.10/dist-packages (from websocket->pyeeg) (22.10.2)\n",
            "Requirement already satisfied: greenlet in /usr/local/lib/python3.10/dist-packages (from websocket->pyeeg) (2.0.2)\n",
            "Requirement already satisfied: zope.event in /usr/local/lib/python3.10/dist-packages (from gevent->websocket->pyeeg) (5.0)\n",
            "Requirement already satisfied: zope.interface in /usr/local/lib/python3.10/dist-packages (from gevent->websocket->pyeeg) (6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from gevent->websocket->pyeeg) (67.7.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "10SzfS3D8vPS"
      },
      "outputs": [],
      "source": [
        "import mne\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the .ftf files\n",
        "raw_meditation = mne.io.read_raw_fif('bass02_meditation_trial1.fif', preload=True)\n",
        "raw_mindwandering = mne.io.read_raw_fif('bass02_mindwandering_trial1.fif', preload=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FdrhssW9lAC",
        "outputId": "d7f21875-20cf-4419-819d-cde7abd86e2a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Opening raw data file bass02_meditation_trial1.fif...\n",
            "    Range : 0 ... 304266 =      0.000 ...  1217.064 secs\n",
            "Ready.\n",
            "Reading 0 ... 304266  =      0.000 ...  1217.064 secs...\n",
            "Opening raw data file bass02_mindwandering_trial1.fif...\n",
            "    Range : 0 ... 313755 =      0.000 ...  1255.020 secs\n",
            "Ready.\n",
            "Reading 0 ... 313755  =      0.000 ...  1255.020 secs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-2d0b0df2413b>:2: RuntimeWarning: This filename (bass02_meditation_trial1.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
            "  raw_meditation = mne.io.read_raw_fif('bass02_meditation_trial1.fif', preload=True)\n",
            "<ipython-input-36-2d0b0df2413b>:3: RuntimeWarning: This filename (bass02_mindwandering_trial1.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
            "  raw_mindwandering = mne.io.read_raw_fif('bass02_mindwandering_trial1.fif', preload=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #Plot\n",
        "# raw_meditation.plot()\n",
        "# raw_mindwandering.plot()"
      ],
      "metadata": {
        "id": "1f_Ff8B0-SH7"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Filter the data\n",
        "raw_meditation.filter(l_freq=1., h_freq=50.)\n",
        "raw_mindwandering.filter(l_freq=1., h_freq=50.)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iy7JktsP-VUs",
        "outputId": "d0b1010f-d352-4088-a4cd-686879d391bf"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 1 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 1.00\n",
            "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 825 samples (3.300 s)\n",
            "\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 1 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 1.00\n",
            "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 825 samples (3.300 s)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Raw | bass02_mindwandering_trial1.fif, 8 x 313756 (1255.0 s), ~19.2 MB, data loaded>"
            ],
            "text/html": [
              "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
              "    <tr>\n",
              "        <th>Measurement date</th>\n",
              "        \n",
              "        <td>Unknown</td>\n",
              "        \n",
              "    </tr>\n",
              "    <tr>\n",
              "        <th>Experimenter</th>\n",
              "        \n",
              "        <td>Unknown</td>\n",
              "        \n",
              "    </tr>\n",
              "        <th>Participant</th>\n",
              "        \n",
              "        <td>Unknown</td>\n",
              "        \n",
              "    </tr>\n",
              "    <tr>\n",
              "        <th>Digitized points</th>\n",
              "        \n",
              "        <td>11 points</td>\n",
              "        \n",
              "    </tr>\n",
              "    <tr>\n",
              "        <th>Good channels</th>\n",
              "        <td>8 EEG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "        <th>Bad channels</th>\n",
              "        <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "        <th>EOG channels</th>\n",
              "        <td>Not available</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "        <th>ECG channels</th>\n",
              "        <td>Not available</td>\n",
              "    \n",
              "    <tr>\n",
              "        <th>Sampling frequency</th>\n",
              "        <td>250.00 Hz</td>\n",
              "    </tr>\n",
              "    \n",
              "    \n",
              "    <tr>\n",
              "        <th>Highpass</th>\n",
              "        <td>1.00 Hz</td>\n",
              "    </tr>\n",
              "    \n",
              "    \n",
              "    <tr>\n",
              "        <th>Lowpass</th>\n",
              "        <td>50.00 Hz</td>\n",
              "    </tr>\n",
              "    \n",
              "    \n",
              "    \n",
              "    <tr>\n",
              "        <th>Filenames</th>\n",
              "        <td>bass02_mindwandering_trial1.fif</td>\n",
              "    </tr>\n",
              "    \n",
              "    <tr>\n",
              "        <th>Duration</th>\n",
              "        <td>00:20:56 (HH:MM:SS)</td>\n",
              "    </tr>\n",
              "</table>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run ICA for artifact rejection\n",
        "ica = mne.preprocessing.ICA(n_components=8, random_state=0)\n",
        "ica.fit(mne.concatenate_raws([raw_meditation, raw_mindwandering]))\n",
        "\n",
        "raw_meditation = ica.apply(raw_meditation)\n",
        "raw_mindwandering = ica.apply(raw_mindwandering)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-FVmLiW-uxd",
        "outputId": "951618c5-c5c3-4874-91b4-2899c531b84a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting ICA to data using 8 channels (please be patient, this may take a while)\n",
            "Selecting by number: 8 components\n",
            "Fitting ICA took 6.4s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (8 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 8 PCA components\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (8 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 8 PCA components\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Plot the raw data after ICA\n",
        "# raw_meditation.plot()\n",
        "# raw_mindwandering.plot()"
      ],
      "metadata": {
        "id": "SRatnMeP_NER"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define epoch parameters\n",
        "tmin, tmax = 0., 1.  # start and end of each epoch in seconds\n",
        "\n",
        "# Define the number of seconds per epoch\n",
        "epoch_secs = 1.\n",
        "\n",
        "# The number of samples per epoch:\n",
        "epoch_samps = int(epoch_secs * raw_meditation.info['sfreq'])\n",
        "\n",
        "# Number of total epochs we'll extract from each dataset:\n",
        "n_epochs_meditation = int(np.floor(len(raw_meditation.times) / epoch_samps))\n",
        "n_epochs_mindwandering = int(np.floor(len(raw_mindwandering.times) / epoch_samps))\n",
        "\n",
        "# Now we'll create the epochs:\n",
        "data_meditation = raw_meditation.get_data()\n",
        "data_mindwandering = raw_mindwandering.get_data()\n",
        "\n",
        "epochs_meditation = []\n",
        "for i in range(n_epochs_meditation):\n",
        "    start = i * epoch_samps\n",
        "    stop = (i + 1) * epoch_samps\n",
        "    epochs_meditation.append(data_meditation[:, start:stop])\n",
        "\n",
        "epochs_mindwandering = []\n",
        "for i in range(n_epochs_mindwandering):\n",
        "    start = i * epoch_samps\n",
        "    stop = (i + 1) * epoch_samps\n",
        "    epochs_mindwandering.append(data_mindwandering[:, start:stop])\n",
        "\n",
        "# Convert lists of epochs to numpy arrays for easier handling later\n",
        "epochs_meditation = np.array(epochs_meditation)\n",
        "epochs_mindwandering = np.array(epochs_mindwandering)\n"
      ],
      "metadata": {
        "id": "BbtqlaJSBWSY"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_alpha_power(epochs, sfreq):\n",
        "    # Define alpha band\n",
        "    low, high = 8, 12\n",
        "\n",
        "    # Compute FFT\n",
        "    freqs = np.fft.rfftfreq(epochs.shape[-1], d=1./sfreq)\n",
        "    fft_vals = np.abs(np.fft.rfft(epochs, axis=-1))\n",
        "\n",
        "    # Find indices corresponding to alpha band\n",
        "    idx_alpha = np.where((freqs >= low) & (freqs <= high))[0]\n",
        "\n",
        "    # Compute mean power in alpha band\n",
        "    alpha_power = fft_vals[..., idx_alpha].mean(axis=-1)\n",
        "\n",
        "    return alpha_power\n",
        "\n",
        "# Compute alpha power for each epoch\n",
        "alpha_power_meditation = compute_alpha_power(epochs_meditation, raw_meditation.info['sfreq'])\n",
        "alpha_power_mindwandering = compute_alpha_power(epochs_mindwandering, raw_mindwandering.info['sfreq'])\n"
      ],
      "metadata": {
        "id": "ltl60w9YDEX3"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Create data and labels\n",
        "X = np.concatenate([alpha_power_meditation, alpha_power_mindwandering])\n",
        "y = np.array([0]*len(alpha_power_meditation) + [1]*len(alpha_power_mindwandering))\n",
        "\n",
        "# Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "A2CfoMbEDiQ8"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Random Forest\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "y_pred_rf = rf_clf.predict(X_test)\n",
        "print(\"Classification report for Random Forest:\")\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "\n",
        "# Non-Linear SVM\n",
        "svm_clf = SVC(kernel='rbf', random_state=42)\n",
        "svm_clf.fit(X_train, y_train)\n",
        "y_pred_svm = svm_clf.predict(X_test)\n",
        "print(\"\\nClassification report for Non-Linear SVM:\")\n",
        "print(classification_report(y_test, y_pred_svm))\n",
        "\n",
        "# Logistic Regression\n",
        "lr_clf = LogisticRegression(random_state=42)\n",
        "lr_clf.fit(X_train, y_train)\n",
        "y_pred_lr = lr_clf.predict(X_test)\n",
        "print(\"\\nClassification report for Logistic Regression:\")\n",
        "print(classification_report(y_test, y_pred_lr))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYIYUDYXFl23",
        "outputId": "32903d33-8e31-46a0-f93e-9504c3931e0f"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report for Random Forest:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.92      0.78       506\n",
            "           1       0.25      0.06      0.09       240\n",
            "\n",
            "    accuracy                           0.64       746\n",
            "   macro avg       0.46      0.49      0.44       746\n",
            "weighted avg       0.54      0.64      0.56       746\n",
            "\n",
            "\n",
            "Classification report for Non-Linear SVM:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      1.00      0.81       506\n",
            "           1       0.00      0.00      0.00       240\n",
            "\n",
            "    accuracy                           0.68       746\n",
            "   macro avg       0.34      0.50      0.40       746\n",
            "weighted avg       0.46      0.68      0.55       746\n",
            "\n",
            "\n",
            "Classification report for Logistic Regression:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      1.00      0.81       506\n",
            "           1       0.00      0.00      0.00       240\n",
            "\n",
            "    accuracy                           0.68       746\n",
            "   macro avg       0.34      0.50      0.40       746\n",
            "weighted avg       0.46      0.68      0.55       746\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bLTYgj9idPpu"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Higuchi"
      ],
      "metadata": {
        "id": "RYuU3kyKdQQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install hfda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsyzpeV7duha",
        "outputId": "433a740b-7c99-4140-8c88-5f8633afce60"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hfda\n",
            "  Downloading hfda-0.1.1.tar.gz (1.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from hfda) (1.22.4)\n",
            "Building wheels for collected packages: hfda\n",
            "  Building wheel for hfda (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hfda: filename=hfda-0.1.1-py3-none-any.whl size=2139 sha256=a81d0f8e5d4c624d8579e4bfbff789fcd4ea7804096160f81a94d96718ab1573\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/2c/72/48f1edf94fa2bf74d8896561391b539909292865a1391aebdd\n",
            "Successfully built hfda\n",
            "Installing collected packages: hfda\n",
            "Successfully installed hfda-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import mne\n",
        "import hfda\n",
        "\n",
        "def compute_hfd_for_each_channel(raw_data, k_max):\n",
        "    # Get data from Raw object\n",
        "    data, times = raw_data[:]\n",
        "\n",
        "    # Compute HFD for each channel\n",
        "    hfd_values = np.array([hfda.measure(channel_data, k_max) for channel_data in data])\n",
        "\n",
        "    return hfd_values\n",
        "\n",
        "# Maximum k for HFD\n",
        "k_max = 5\n",
        "\n",
        "# Load the .fif files\n",
        "raw_meditation = mne.io.read_raw_fif('bass02_meditation_trial1.fif', preload=True)\n",
        "raw_mindwandering = mne.io.read_raw_fif('bass02_mindwandering_trial1.fif', preload=True)\n",
        "\n",
        "# Compute HFD for each channel for each condition\n",
        "hfd_meditation = compute_hfd_for_each_channel(raw_meditation, k_max)\n",
        "hfd_mindwandering = compute_hfd_for_each_channel(raw_mindwandering, k_max)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sf489GH8HLSd",
        "outputId": "8574d2a5-29ea-4f67-b558-b029db95e798"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Opening raw data file bass02_meditation_trial1.fif...\n",
            "    Range : 0 ... 304266 =      0.000 ...  1217.064 secs\n",
            "Ready.\n",
            "Reading 0 ... 304266  =      0.000 ...  1217.064 secs...\n",
            "Opening raw data file bass02_mindwandering_trial1.fif...\n",
            "    Range : 0 ... 313755 =      0.000 ...  1255.020 secs\n",
            "Ready.\n",
            "Reading 0 ... 313755  =      0.000 ...  1255.020 secs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-49-85db815d58c4>:18: RuntimeWarning: This filename (bass02_meditation_trial1.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
            "  raw_meditation = mne.io.read_raw_fif('bass02_meditation_trial1.fif', preload=True)\n",
            "<ipython-input-49-85db815d58c4>:19: RuntimeWarning: This filename (bass02_mindwandering_trial1.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
            "  raw_mindwandering = mne.io.read_raw_fif('bass02_mindwandering_trial1.fif', preload=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nolds pyefd\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1OZw4n6dWlG",
        "outputId": "09cc7a65-cbf1-46c6-f012-bb7eaa70aca9"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nolds\n",
            "  Downloading nolds-0.5.2-py2.py3-none-any.whl (39 kB)\n",
            "Collecting pyefd\n",
            "  Downloading pyefd-1.6.0-py2.py3-none-any.whl (7.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from nolds) (1.22.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from nolds) (0.18.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nolds) (67.7.2)\n",
            "Installing collected packages: pyefd, nolds\n",
            "Successfully installed nolds-0.5.2 pyefd-1.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Detrended Fluctuation Analysis (DFA)"
      ],
      "metadata": {
        "id": "1UT_k1tlyfw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nolds\n",
        "\n",
        "# Get the data from the MNE Raw object\n",
        "data, times = raw_meditation.get_data(return_times=True)\n",
        "\n",
        "# Compute DFA for each channel\n",
        "for i, channel_data in enumerate(data):\n",
        "    alpha = nolds.dfa(channel_data)\n",
        "    print(f'DFA alpha for channel {i+1}: {alpha}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXNOT9ZOfk5b",
        "outputId": "db74355a-0ef2-4192-bd7d-957baa78632a"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DFA alpha for channel 1: 1.6747522170213065\n",
            "DFA alpha for channel 2: 1.5348684324761481\n",
            "DFA alpha for channel 3: 1.5754153313713244\n",
            "DFA alpha for channel 4: 1.5518711121192026\n",
            "DFA alpha for channel 5: 1.569262767170263\n",
            "DFA alpha for channel 6: 1.535570653667137\n",
            "DFA alpha for channel 7: 1.7691293917542465\n",
            "DFA alpha for channel 8: 1.6121688339807632\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/forrestbao/pyeeg.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmYLjQJhvUpw",
        "outputId": "fc33d118-ed5f-4d83-faec-a39e71e1f8bb"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/forrestbao/pyeeg.git\n",
            "  Cloning https://github.com/forrestbao/pyeeg.git to /tmp/pip-req-build-7da8nohi\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/forrestbao/pyeeg.git /tmp/pip-req-build-7da8nohi\n",
            "  Resolved https://github.com/forrestbao/pyeeg.git to commit a6c18bb093e4748f9d9c208535a6ae024a0802b8\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from pyeeg==0.4.4) (1.22.4)\n",
            "Building wheels for collected packages: pyeeg\n",
            "  Building wheel for pyeeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyeeg: filename=pyeeg-0.4.4-py2.py3-none-any.whl size=28114 sha256=dd3e73a5ba03082341717101d245895613e68161862e05fa197c3ca489f13cd9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-bct797yu/wheels/a8/c4/1a/cee09dcc12a11620066d35ace42e3c1e3bfbcc1db3a0ce7788\n",
            "Successfully built pyeeg\n",
            "Installing collected packages: pyeeg\n",
            "  Attempting uninstall: pyeeg\n",
            "    Found existing installation: pyeeg 0.0.2\n",
            "    Uninstalling pyeeg-0.0.2:\n",
            "      Successfully uninstalled pyeeg-0.0.2\n",
            "Successfully installed pyeeg-0.4.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Petitjean Fractal Dimension (PFD)"
      ],
      "metadata": {
        "id": "vVeOVXFqydU1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyeeg\n",
        "\n",
        "# Get the data from the MNE Raw object\n",
        "data, times = raw_meditation.get_data(return_times=True)\n",
        "\n",
        "# Compute PFD for each channel\n",
        "for i, channel_data in enumerate(data):\n",
        "    pfd = pyeeg.pfd(channel_data)\n",
        "    print(f'PFD for channel {i+1}: {pfd}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yC23P5qCfo7u",
        "outputId": "2492fddf-4b5c-42c6-a769-7782969f8f03"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PFD for channel 1: 0.5387028416255876\n",
            "PFD for channel 2: 0.5383421575727636\n",
            "PFD for channel 3: 0.5392007231679988\n",
            "PFD for channel 4: 0.5373809743799763\n",
            "PFD for channel 5: 0.5384908702213497\n",
            "PFD for channel 6: 0.5375407654143107\n",
            "PFD for channel 7: 0.5372223855986799\n",
            "PFD for channel 8: 0.5373359137945707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample Entropy"
      ],
      "metadata": {
        "id": "LyDV-i7bzfLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nolds\n",
        "from pyeeg import ap_entropy\n",
        "\n",
        "# Constants for Approximate Entropy\n",
        "m = 2  # The length of compared run of data\n",
        "r = 0.2 * np.std(data)  # The tolerance (generally 0.1...0.25 times the standard deviation of the data)\n",
        "\n",
        "# Get the data from the MNE Raw object\n",
        "meditation_data, _ = raw_meditation.get_data(return_times=True)\n",
        "mindwandering_data, _ = raw_mindwandering.get_data(return_times=True)\n",
        "\n",
        "for i in range(meditation_data.shape[0]):  # Assuming your data is 2D with the shape (channels, time)\n",
        "    channel_data_meditation = meditation_data[i]\n",
        "    channel_data_mindwandering = mindwandering_data[i]\n",
        "\n",
        "    # Calculate Sample Entropy\n",
        "    sampen_meditation = nolds.sampen(channel_data_meditation)\n",
        "    sampen_mindwandering = nolds.sampen(channel_data_mindwandering)\n",
        "\n",
        "    print(f'Sample Entropy for Meditation channel {i+1}: {sampen_meditation}')\n",
        "    print(f'Sample Entropy for Mind-Wandering channel {i+1}: {sampen_mindwandering}')\n",
        "\n",
        "    # Calculate Approximate Entropy\n",
        "    apen_meditation = ap_entropy(channel_data_meditation, m, r)\n",
        "    apen_mindwandering = ap_entropy(channel_data_mindwandering, m, r)\n",
        "\n",
        "    print(f'Approximate Entropy for Meditation channel {i+1}: {apen_meditation}')\n",
        "    print(f'Approximate Entropy for Mind-Wandering channel {i+1}: {apen_mindwandering}')\n"
      ],
      "metadata": {
        "id": "CCzqE4W4tldV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o9NBwZa0ziAh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}